\section{Conclusioni}
Riassumendo, l’analisi del dataset si è ripetutamente scontrata con il suo alto sbilanciamento e la presenza di dati mancanti o corrotti, già rilevati nella fase di \textit{Data understanding}.\\\\
Nella fase di \textit{Data preparation} si è cercato limitare il problema, rimuovendo i parametri giudicati poco utili, stimando i possibili valori mancanti nelle varie \textit{feature} e generando due nuove \textit{feature} \textit{ad hoc}, che si sono in seguito rivelate utili. Nel complesso, i 1176 oggetti descritti da 33 attributi sono stati ridotti a 1029 oggetti descritti da 13 attributi.\\\\
Il clustering dei dati è risultato tuttavia comunque problematico per il generale sbilanciamento degli oggetti con \textit{Attrition} pari \textit{No} e la presenza di rumore. Dei vari modelli testati, solo il \textit{K-Means} ha portato a dei buoni risultati. \\\\
Successivamente si è proceduto alla classificazione dei dati. Nuovamente, le problematiche descritte sopra hanno portato gli algoritmi di \textit{Decision tree} e \textit{KNN} a generare risultati poco soddisfacenti. Di contro, il metodo \textit{Random forest}, accompagnato da un \textit{oversampling} del dataset, è risultato efficace e ha permesso di comprendere quali attributi potessero maggiormente determinare l’\textit{Attrition}: \textit{OverTime}, \textit{JobLevel}, \textit{GeneralEmployeeSatisfaction} e \textit{DistanceFromHome}. È stato inoltre addestrato un modello per la predizione della \textit{target variable}, che, tuttavia, non ha fornito risultati accurati. \\\\
Eventuali sviluppi futuri potrebbero vedere l’applicazione di altri algoritmi o in alternativa l’ampliamento dell’attuale dataset, per avere una prospettiva meno sbilanciata dei lavoratori IBM, permettendo,  anche soltanto con le metodologie testate in questo \textit{paper}, di ottenere risultati più accurati.


